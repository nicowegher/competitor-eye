#!/usr/bin/env python3
"""
Script de prueba para verificar el funcionamiento del scraper mejorado
"""

import requests
import json
import time
from datetime import datetime

# Configuraci√≥n
BASE_URL = "https://tu-app-en-render.onrender.com"  # Cambiar por tu URL de Render
TEST_DATA = {
    "ownHotelUrl": "https://www.booking.com/hotel/ar/el-pueblito-iguazu.es.html?selected_currency=USD",
    "competitorHotelUrls": [
        "https://www.booking.com/hotel/ar/guamini-mision-puerto-iguazu6.es.html?selected_currency=USD"
    ],
    "daysToScrape": 1
}

def test_health_check():
    """Prueba el endpoint de health check"""
    print("üîç Probando health check...")
    try:
        response = requests.get(f"{BASE_URL}/")
        if response.status_code == 200:
            print("‚úÖ Health check exitoso")
            print(f"   Respuesta: {response.json()}")
            return True
        else:
            print(f"‚ùå Health check fall√≥: {response.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå Error en health check: {e}")
        return False

def test_scraper_start():
    """Prueba iniciar el scraper"""
    print("\nüöÄ Probando inicio del scraper...")
    try:
        response = requests.post(
            f"{BASE_URL}/run-scraper",
            json=TEST_DATA,
            headers={"Content-Type": "application/json"}
        )
        
        print(f"   Status Code: {response.status_code}")
        print(f"   Respuesta: {response.json()}")
        
        if response.status_code == 200:
            print("‚úÖ Scraper iniciado correctamente")
            return True
        else:
            print("‚ùå Error al iniciar scraper")
            return False
            
    except Exception as e:
        print(f"‚ùå Error al iniciar scraper: {e}")
        return False

def test_scraper_status():
    """Prueba el endpoint de status del scraper"""
    print("\nüìä Probando status del scraper...")
    try:
        response = requests.get(f"{BASE_URL}/scraper-status")
        
        if response.status_code == 200:
            status = response.json()
            print("‚úÖ Status obtenido correctamente")
            print(f"   Estado: {status}")
            return status
        else:
            print(f"‚ùå Error al obtener status: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå Error al obtener status: {e}")
        return None

def monitor_scraper_progress(max_wait_time=300):
    """Monitorea el progreso del scraper"""
    print(f"\n‚è±Ô∏è  Monitoreando progreso (m√°ximo {max_wait_time}s)...")
    
    start_time = time.time()
    last_status = None
    
    while time.time() - start_time < max_wait_time:
        status = test_scraper_status()
        
        if status:
            # Verificar si el estado cambi√≥
            if status != last_status:
                print(f"\nüìà Estado actualizado:")
                print(f"   Ejecut√°ndose: {status.get('is_running', 'N/A')}")
                print(f"   Progreso: {status.get('progress', 'N/A')}%")
                print(f"   Error: {status.get('error', 'Ninguno')}")
                
                if status.get('result'):
                    print(f"   ‚úÖ Scraper completado!")
                    print(f"   CSV URL: {status['result'].get('csvFileUrl', 'N/A')}")
                    print(f"   XLSX URL: {status['result'].get('xlsxFileUrl', 'N/A')}")
                    return True
                
                if status.get('error'):
                    print(f"   ‚ùå Scraper fall√≥: {status['error']}")
                    return False
                
                last_status = status
        
        # Esperar 10 segundos antes de la siguiente verificaci√≥n
        time.sleep(10)
    
    print("‚è∞ Tiempo de espera agotado")
    return False

def test_download_endpoints():
    """Prueba los endpoints de descarga"""
    print("\nüì• Probando endpoints de descarga...")
    
    endpoints = [
        ("/datos", "GET"),
        ("/descargar-csv", "GET"),
        ("/descargar-excel", "GET")
    ]
    
    for endpoint, method in endpoints:
        try:
            if method == "GET":
                response = requests.get(f"{BASE_URL}{endpoint}")
            else:
                response = requests.post(f"{BASE_URL}{endpoint}")
            
            print(f"   {method} {endpoint}: {response.status_code}")
            
            if response.status_code == 200:
                print(f"   ‚úÖ {endpoint} funciona correctamente")
            else:
                print(f"   ‚ö†Ô∏è  {endpoint} retorn√≥ {response.status_code}")
                
        except Exception as e:
            print(f"   ‚ùå Error en {endpoint}: {e}")

def main():
    """Funci√≥n principal de pruebas"""
    print("üß™ INICIANDO PRUEBAS DEL SCRAPER MEJORADO")
    print("=" * 50)
    print(f"URL Base: {BASE_URL}")
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    # Prueba 1: Health Check
    if not test_health_check():
        print("\n‚ùå Health check fall√≥. Verificar que la aplicaci√≥n est√© corriendo.")
        return
    
    # Prueba 2: Endpoints de descarga
    test_download_endpoints()
    
    # Prueba 3: Iniciar scraper
    if not test_scraper_start():
        print("\n‚ùå No se pudo iniciar el scraper.")
        return
    
    # Prueba 4: Monitorear progreso
    success = monitor_scraper_progress(max_wait_time=300)  # 5 minutos m√°ximo
    
    if success:
        print("\nüéâ ¬°TODAS LAS PRUEBAS EXITOSAS!")
        print("El scraper mejorado est√° funcionando correctamente.")
    else:
        print("\n‚ö†Ô∏è  Algunas pruebas fallaron o el scraper no complet√≥ en tiempo.")
    
    print("\n" + "=" * 50)
    print("FIN DE PRUEBAS")

if __name__ == "__main__":
    main() 